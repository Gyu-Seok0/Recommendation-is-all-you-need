{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e216e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Base code : https://yamalab.tistory.com/92\n",
    "class MatrixFactorization():\n",
    "    def __init__(self, R, k, learning_rate, reg_param, epochs, verbose=False):\n",
    "        \"\"\"\n",
    "        :param R: rating matrix\n",
    "        :param k: latent parameter\n",
    "        :param learning_rate: alpha on weight update\n",
    "        :param reg_param: beta on weight update\n",
    "        :param epochs: training epochs\n",
    "        :param verbose: print status\n",
    "        \"\"\"\n",
    "        self._R = R\n",
    "        self._num_users, self._num_items = R.shape\n",
    "        self._k = k\n",
    "        self._learning_rate = learning_rate\n",
    "        self._reg_param = reg_param\n",
    "        self._epochs = epochs\n",
    "        self._verbose = verbose\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        training Matrix Factorization : Update matrix latent weight and bias\n",
    "\n",
    "        참고: self._b에 대한 설명\n",
    "        - global bias: input R에서 평가가 매겨진 rating의 평균값을 global bias로 사용\n",
    "        - 정규화 기능. 최종 rating에 음수가 들어가는 것 대신 latent feature에 음수가 포함되도록 해줌.\n",
    "\n",
    "        :return: training_process\n",
    "        \"\"\"\n",
    "\n",
    "        # init latent features\n",
    "        self._P = np.random.normal(size=(self._num_users, self._k))\n",
    "        self._Q = np.random.normal(size=(self._num_items, self._k))\n",
    "\n",
    "        # init biases\n",
    "        self._b_P = np.zeros(self._num_users)\n",
    "        self._b_Q = np.zeros(self._num_items)\n",
    "        self._b = np.mean(self._R[np.where(self._R != 0)]) # rating의 평균이라고 생각하면 된다.\n",
    "\n",
    "        # train while epochs\n",
    "        self._training_process = []\n",
    "        for epoch in range(self._epochs):\n",
    "            # rating이 존재하는 index를 기준으로 training\n",
    "            xi, yi = self._R.nonzero()\n",
    "            for i, j in zip(xi, yi):\n",
    "                self.gradient_descent(i, j, self._R[i, j])\n",
    "            cost = self.cost()\n",
    "            self._training_process.append((epoch, cost))\n",
    "\n",
    "            # print status\n",
    "            if self._verbose == True and ((epoch + 1) % 10 == 0):\n",
    "                print(\"Iteration: %d ; cost = %.4f\" % (epoch + 1, cost))\n",
    "\n",
    "\n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        compute root mean square error\n",
    "        :return: rmse cost\n",
    "        \"\"\"\n",
    "\n",
    "        # xi, yi: R[xi, yi]는 nonzero인 value를 의미한다.\n",
    "        # 참고: http://codepractice.tistory.com/90\n",
    "        xi, yi = self._R.nonzero()\n",
    "        # predicted = self.get_complete_matrix()\n",
    "        cost = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            cost += pow(self._R[x, y] - self.get_prediction(x, y), 2)\n",
    "        return np.sqrt(cost/len(xi))\n",
    "\n",
    "\n",
    "    def gradient(self, error, i, j):\n",
    "        \"\"\"\n",
    "        gradient of latent feature for GD\n",
    "\n",
    "        :param error: rating - prediction error\n",
    "        :param i: user index\n",
    "        :param j: item index\n",
    "        :return: gradient of latent feature tuple\n",
    "        \"\"\"\n",
    "\n",
    "        dp = (error * self._Q[j, :]) - (self._reg_param * self._P[i, :])\n",
    "        dq = (error * self._P[i, :]) - (self._reg_param * self._Q[j, :])\n",
    "        return dp, dq\n",
    "\n",
    "\n",
    "    def gradient_descent(self, i, j, rating):\n",
    "        \"\"\"\n",
    "        graident descent function\n",
    "\n",
    "        :param i: user index of matrix\n",
    "        :param j: item index of matrix\n",
    "        :param rating: rating of (i,j)\n",
    "        \"\"\"\n",
    "\n",
    "        # get error\n",
    "        prediction = self.get_prediction(i, j)\n",
    "        error = rating - prediction\n",
    "\n",
    "        # update biases\n",
    "        self._b_P[i] += self._learning_rate * (error - self._reg_param * self._b_P[i])\n",
    "        self._b_Q[j] += self._learning_rate * (error - self._reg_param * self._b_Q[j])\n",
    "\n",
    "        # update latent feature\n",
    "        dp, dq = self.gradient(error, i, j)\n",
    "        self._P[i, :] += self._learning_rate * dp\n",
    "        self._Q[j, :] += self._learning_rate * dq\n",
    "\n",
    "\n",
    "    def get_prediction(self, i, j):\n",
    "        \"\"\"\n",
    "        get predicted rating: user_i, item_j\n",
    "        :return: prediction of r_ij\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[i] + self._b_Q[j] + self._P[i, :].dot(self._Q[j, :].T)\n",
    "\n",
    "\n",
    "    def get_complete_matrix(self):\n",
    "        \"\"\"\n",
    "        computer complete matrix PXQ + P.bias + Q.bias + global bias\n",
    "\n",
    "        - PXQ 행렬에 b_P[:, np.newaxis]를 더하는 것은 각 열마다 bias를 더해주는 것\n",
    "        - b_Q[np.newaxis:, ]를 더하는 것은 각 행마다 bias를 더해주는 것\n",
    "        - b를 더하는 것은 각 element마다 bias를 더해주는 것\n",
    "\n",
    "        - newaxis: 차원을 추가해줌. 1차원인 Latent들로 2차원의 R에 행/열 단위 연산을 해주기위해 차원을 추가하는 것.\n",
    "\n",
    "        :return: complete matrix R^\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[:, np.newaxis] + self._b_Q[np.newaxis:, ] + self._P.dot(self._Q.T)\n",
    "        #각각의 차원 1 + (7,1) + (5,) + (7*3)*(3*5)\n",
    "\n",
    "\n",
    "# run example\n",
    "if __name__ == \"__main__\":\n",
    "    # rating matrix - User X Item : (7 X 5)\n",
    "    R = np.array([\n",
    "        [1, 0, 0, 1, 3],\n",
    "        [2, 0, 3, 1, 1],\n",
    "        [1, 2, 0, 5, 0],\n",
    "        [1, 0, 0, 4, 4],\n",
    "        [2, 1, 5, 4, 0],\n",
    "        [5, 1, 5, 4, 0],\n",
    "        [0, 0, 0, 1, 0],\n",
    "    ])\n",
    "\n",
    "    # P, Q is (7 X k), (k X 5) matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c64bce5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; cost = 1.0226\n",
      "Iteration: 20 ; cost = 0.7377\n",
      "Iteration: 30 ; cost = 0.5838\n",
      "Iteration: 40 ; cost = 0.4783\n",
      "Iteration: 50 ; cost = 0.3979\n",
      "Iteration: 60 ; cost = 0.3344\n",
      "Iteration: 70 ; cost = 0.2837\n",
      "Iteration: 80 ; cost = 0.2430\n",
      "Iteration: 90 ; cost = 0.2102\n",
      "Iteration: 100 ; cost = 0.1834\n",
      "CPU times: user 199 ms, sys: 73.9 ms, total: 273 ms\n",
      "Wall time: 93.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "factorizer = MatrixFactorization(R, k=3, learning_rate=0.01, reg_param=0.01, epochs=100, verbose=True)\n",
    "factorizer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4367e0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; cost = 0.9269\n",
      "Iteration: 20 ; cost = 0.6318\n",
      "Iteration: 30 ; cost = 0.4814\n",
      "Iteration: 40 ; cost = 0.3783\n",
      "Iteration: 50 ; cost = 0.3009\n",
      "Iteration: 60 ; cost = 0.2412\n",
      "Iteration: 70 ; cost = 0.1951\n",
      "Iteration: 80 ; cost = 0.1597\n",
      "Iteration: 90 ; cost = 0.1328\n",
      "Iteration: 100 ; cost = 0.1124\n",
      "CPU times: user 94.1 ms, sys: 23.6 ms, total: 118 ms\n",
      "Wall time: 97.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "factorizer = MatrixFactorization(R, k=3, learning_rate=0.01, reg_param=0.01, epochs=100, verbose=True)\n",
    "factorizer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2880fe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.84,  4.3 ,  0.87,  1.07,  3.16],\n",
       "       [ 2.04,  1.71,  2.76,  1.27,  1.03],\n",
       "       [ 0.98,  2.  ,  5.08,  5.  ,  1.09],\n",
       "       [ 1.13,  2.24,  1.99,  3.93,  3.87],\n",
       "       [ 2.05,  0.99,  5.07,  3.9 ,  0.51],\n",
       "       [ 4.92,  0.99,  5.1 ,  3.88,  2.76],\n",
       "       [ 2.03,  0.14, -0.81,  1.02,  4.25]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측값\n",
    "np.round(factorizer.get_complete_matrix(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3889adaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 3],\n",
       "       [2, 0, 3, 1, 1],\n",
       "       [1, 2, 0, 5, 0],\n",
       "       [1, 0, 0, 4, 4],\n",
       "       [2, 1, 5, 4, 0],\n",
       "       [5, 1, 5, 4, 0],\n",
       "       [0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ground Truth\n",
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25dbdc8",
   "metadata": {},
   "source": [
    "# ALS 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5d27ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# Base code : https://github.com/mickeykedia/Matrix-Factorization-ALS/blob/master/ALS%20Python%20Implementation.py\n",
    "class AlternatingLeastSquares():\n",
    "    def __init__(self, R, k, reg_param, epochs, verbose=False):\n",
    "        \"\"\"\n",
    "        :param R: rating matrix\n",
    "        :param k: latent parameter\n",
    "        :param learning_rate: alpha on weight update\n",
    "        :param reg_param: beta on weight update\n",
    "        :param epochs: training epochs\n",
    "        :param verbose: print status\n",
    "        \"\"\"\n",
    "        self._R = R\n",
    "        self._num_users, self._num_items = R.shape\n",
    "        self._k = k\n",
    "        self._reg_param = reg_param\n",
    "        self._epochs = epochs\n",
    "        self._verbose = verbose\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        # init latent features\n",
    "        self._users = np.random.normal(size=(self._num_users, self._k))\n",
    "        self._items = np.random.normal(size=(self._num_items, self._k))\n",
    "\n",
    "        # train while epochs\n",
    "        self._training_process = []\n",
    "        self._user_error = 0; self._item_error = 0; \n",
    "        for epoch in range(self._epochs):\n",
    "            for i, Ri in enumerate(self._R):\n",
    "                self._users[i] = self.user_latent(i, Ri)\n",
    "                self._user_error = self.cost()\n",
    "                \n",
    "            for j, Rj in enumerate(self._R.T):\n",
    "                self._items[j] = self.item_latent(j, Rj)\n",
    "                self._item_error = self.cost()\n",
    "                \n",
    "            cost = self.cost()\n",
    "            self._training_process.append((epoch, cost))\n",
    "\n",
    "            # print status\n",
    "            if self._verbose == True and ((epoch + 1) % 10 == 0):\n",
    "                print(\"Iteration: %d ; cost = %.4f\" % (epoch + 1, cost))\n",
    "\n",
    "\n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        compute root mean square error\n",
    "        :return: rmse cost\n",
    "        \"\"\"\n",
    "        xi, yi = self._R.nonzero()\n",
    "        cost = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            cost += pow(self._R[x, y] - self.get_prediction(x, y), 2)\n",
    "        return np.sqrt(cost/len(xi))\n",
    "\n",
    "\n",
    "    def user_latent(self, i, Ri):\n",
    "        \"\"\"\n",
    "        :param error: rating - prediction error\n",
    "        :param i: user index\n",
    "        :param Ri: Rating of user index i\n",
    "        :return: convergence value of user latent of i index\n",
    "        \"\"\"\n",
    "\n",
    "        du = np.linalg.solve(np.dot(self._items.T, np.dot(np.diag(Ri), self._items)) + self._reg_param * np.eye(self._k),\n",
    "                                   np.dot(self._items.T, np.dot(np.diag(Ri), self._R[i].T))).T\n",
    "        return du\n",
    "\n",
    "    def item_latent(self, j, Rj):\n",
    "        \"\"\"\n",
    "        :param error: rating - prediction error\n",
    "        :param j: item index\n",
    "        :param Rj: Rating of item index j\n",
    "        :return: convergence value of itemr latent of j index\n",
    "        \"\"\"\n",
    "\n",
    "        di = np.linalg.solve(np.dot(self._users.T, np.dot(np.diag(Rj), self._users)) + self._reg_param * np.eye(self._k),\n",
    "                                 np.dot(self._users.T, np.dot(np.diag(Rj), self._R[:, j])))\n",
    "        return di\n",
    "\n",
    "\n",
    "    def get_prediction(self, i, j):\n",
    "        \"\"\"\n",
    "        get predicted rating: user_i, item_j\n",
    "        :return: prediction of r_ij\n",
    "        \"\"\"\n",
    "        return self._users[i, :].dot(self._items[j, :].T)\n",
    "\n",
    "\n",
    "    def get_complete_matrix(self):\n",
    "        \"\"\"\n",
    "        :return: complete matrix R^\n",
    "        \"\"\"\n",
    "        return self._users.dot(self._items.T)\n",
    "\n",
    "\n",
    "\n",
    "# run example\n",
    "if __name__ == \"__main__\":\n",
    "    # rating matrix - User X Item : (7 X 5)\n",
    "    R = np.array([\n",
    "        [1, 0, 0, 1, 3],\n",
    "        [2, 0, 3, 1, 1],\n",
    "        [1, 2, 0, 5, 0],\n",
    "        [1, 0, 0, 4, 4],\n",
    "        [2, 1, 5, 4, 0],\n",
    "        [5, 1, 5, 4, 0],\n",
    "        [0, 0, 0, 1, 0],\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30f3a047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; cost = 0.0214\n",
      "Iteration: 20 ; cost = 0.0128\n",
      "Iteration: 30 ; cost = 0.0100\n",
      "Iteration: 40 ; cost = 0.0084\n",
      "Iteration: 50 ; cost = 0.0074\n",
      "Iteration: 60 ; cost = 0.0066\n",
      "Iteration: 70 ; cost = 0.0060\n",
      "Iteration: 80 ; cost = 0.0055\n",
      "Iteration: 90 ; cost = 0.0051\n",
      "Iteration: 100 ; cost = 0.0048\n"
     ]
    }
   ],
   "source": [
    "als = AlternatingLeastSquares(R = R, reg_param = 0.01, epochs=100, verbose=True, k=3)\n",
    "als.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "966aa008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1., -2.,  1.,  3.],\n",
       "       [ 2., -0.,  3.,  1.,  1.],\n",
       "       [ 1.,  2.,  2.,  5., -0.],\n",
       "       [ 1.,  3., -4.,  4.,  4.],\n",
       "       [ 2.,  1.,  5.,  4., -1.],\n",
       "       [ 5.,  1.,  5.,  4.,  4.],\n",
       "       [-0.,  0.,  0.,  1., -0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(als.get_complete_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0180f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 3],\n",
       "       [2, 0, 3, 1, 1],\n",
       "       [1, 2, 0, 5, 0],\n",
       "       [1, 0, 0, 4, 4],\n",
       "       [2, 1, 5, 4, 0],\n",
       "       [5, 1, 5, 4, 0],\n",
       "       [0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc70895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
