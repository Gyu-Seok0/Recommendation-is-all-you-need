{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29277a5",
   "metadata": {},
   "source": [
    "# 목적\n",
    "간단한 movie lens data를 토대로 MF를 구현해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "14be7c2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Failed to open file b'C:\\\\Users\\\\\\xec\\x9d\\xb4\\xea\\xb7\\x9c\\xec\\x84\\x9d\\\\AppData\\\\Local\\\\Temp\\\\scipy-719m9xp6'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [76]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mpath\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\이규석\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\__init__.py:82\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _distributor_init  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __check_build  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     85\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    129\u001b[0m ]\n",
      "File \u001b[1;32mc:\\users\\이규석\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tags\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     _DEFAULT_TAGS,\n\u001b[0;32m     20\u001b[0m     _safe_tags,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n",
      "File \u001b[1;32mc:\\users\\이규석\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\__init__.py:28\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m np_version, parse_version\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     31\u001b[0m     as_float_array,\n\u001b[0;32m     32\u001b[0m     assert_all_finite,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     check_scalar,\n\u001b[0;32m     41\u001b[0m )\n",
      "File \u001b[1;32mc:\\users\\이규석\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\fixes.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lsqr \u001b[38;5;28;01mas\u001b[39;00m sparse_lsqr  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreadpoolctl\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\이규석\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\stats\\__init__.py:468\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_entropy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_hypotests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m--> 468\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rvs_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rvs_ratio_uniforms, NumericalInverseHermite  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_page_trend_test\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m page_trend_test\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_mannwhitneyu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mannwhitneyu\n",
      "File \u001b[1;32mc:\\users\\이규석\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\stats\\_rvs_sampling.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_unuran\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unuran_wrapper\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _deprecated\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n",
      "File \u001b[1;32munuran_wrapper.pyx:221\u001b[0m, in \u001b[0;36minit scipy.stats._unuran.unuran_wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32munuran_wrapper.pyx:200\u001b[0m, in \u001b[0;36mscipy.stats._unuran.unuran_wrapper._setup_unuran\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mmessagestream.pyx:36\u001b[0m, in \u001b[0;36mscipy._lib.messagestream.MessageStream.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Failed to open file b'C:\\\\Users\\\\\\xec\\x9d\\xb4\\xea\\xb7\\x9c\\xec\\x84\\x9d\\\\AppData\\\\Local\\\\Temp\\\\scipy-719m9xp6'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.path\n",
    "os.getcwd()\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "beae5dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"../ml-100k/u.data\", sep = \"\\t\", names = [\"user_id\",\"item_id\",\"rating\",\"timestamp\"])\n",
    "data[\"user_id\"] -= 1\n",
    "data[\"item_id\"] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ed2a1ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"item_id\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3775d716",
   "metadata": {},
   "source": [
    "# 숫자 세기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "818c17cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of user = 943, num of item = 1682\n"
     ]
    }
   ],
   "source": [
    "num_u = len(data.user_id.unique())\n",
    "num_i = len(data.item_id.unique())\n",
    "print(f\"num of user = {num_u}, num of item = {num_i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8b86e0",
   "metadata": {},
   "source": [
    "# Embedding layer 만들기(예제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6df55939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "train_data = \"you need to know how to code\"\n",
    "word_set = set(train_data.split())\n",
    "\n",
    "# 단어:정수 Mapping\n",
    "vocab = {tkn:i+1 for i,tkn in enumerate(word_set)}\n",
    "vocab[\"<unk>\"] = 0\n",
    "vocab[\"<pad>\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab37e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "embedding_layer = nn.Embedding(num_embeddings = len(vocab),\n",
    "                                 embedding_dim= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ae02bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3533, -0.6809,  0.0570],\n",
      "        [-0.7022, -0.4409,  1.3236],\n",
      "        [ 1.4935, -0.6087, -1.1500],\n",
      "        [-0.1488, -1.2238, -0.2130],\n",
      "        [ 0.3307, -0.1288, -0.3771],\n",
      "        [ 0.8183, -2.1404,  0.6579],\n",
      "        [-0.0777,  0.2698,  0.5897],\n",
      "        [-0.1392, -1.4386,  2.1440]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51158c5",
   "metadata": {},
   "source": [
    "# Embedding layer (추천용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeb9d9b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of user_em = Embedding(943, 10)\n",
      "Shape of item_em = Embedding(1682, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 10\n",
    "user_em = nn.Embedding(num_embeddings = num_u,\n",
    "                       embedding_dim = dim)\n",
    "item_em = nn.Embedding(num_embeddings = num_i,\n",
    "                      embedding_dim = dim)\n",
    "print(f\"Shape of user_em = {user_em}\")\n",
    "print(f\"Shape of item_em = {item_em}\")\n",
    "\n",
    "user_em.weight[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31c30073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2491,  0.8586, -0.4791,  ..., -0.8219, -0.9680, -1.1361],\n",
       "        [-1.2656, -0.9125,  0.7880,  ..., -2.0837, -0.8036,  0.6981],\n",
       "        [ 1.7814,  0.4080, -0.7263,  ...,  0.8307,  0.5983,  1.0917],\n",
       "        ...,\n",
       "        [-1.5697,  0.7081,  0.5688,  ..., -2.0373, -0.4802,  1.0645],\n",
       "        [-0.6605,  0.9007, -1.1356,  ...,  0.2431,  1.0616,  0.6796],\n",
       "        [-1.2818,  0.7275, -0.8573,  ...,  0.9400,  0.5014, -0.5487]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_em.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5523afc",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "954d65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#어떻게 파라미터를 update 시키지 -> freeze 시키면 되는듯..?\n",
    "\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, num_u:int, num_i:int, dim:int):\n",
    "        super().__init__()\n",
    "        self.user_em = nn.Embedding(num_embeddings = num_u, embedding_dim = dim)\n",
    "        self.item_em = nn.Embedding(num_embeddings = num_i, embedding_dim = dim)\n",
    "        nn.init.normal_(self.user_em.weight, mean = 0, std = 0.01)\n",
    "        nn.init.normal_(self.item_em.weight, mean = 0, std = 0.01)\n",
    "    \n",
    "    def forward(self,user,item):\n",
    "        return torch.dot(self.user_em.weight[user], self.item_em.weight[item])\n",
    "\n",
    "model = MF(num_u, num_i, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4f44b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"user_id\",\"item_id\"]]\n",
    "Y = data[\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "da420171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "test_idx = random.sample(range(len(data)), int(len(data)*0.2 ))\n",
    "\n",
    "test = data.iloc[test_idx,:]\n",
    "train = data.drop(test_idx).sample(frac = 1) # 셔플시켜줌\n",
    "\n",
    "X_test, Y_test = test[[\"user_id\",\"item_id\"]].values.tolist(), test[\"rating\"].tolist()\n",
    "X_train, Y_train = train[[\"user_id\",\"item_id\"]].values.tolist(), train[\"rating\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5208ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train = (80000, 80000)\n",
      "Test = (20000, 20000)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train = {len(X_train), len(Y_train)}\")\n",
    "print(f\"Test = {len(X_test), len(Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00183e9c",
   "metadata": {},
   "source": [
    "# 한번 돌려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6817ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "learing_rate = 0.1\n",
    "training_epoch = 2\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learing_rate, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2798066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0120, -0.0089, -0.0123,  ...,  0.0067, -0.0052, -0.0056],\n",
      "        [-0.0143,  0.0024,  0.0089,  ...,  0.0029,  0.0049, -0.0067],\n",
      "        [-0.0029, -0.0064,  0.0002,  ..., -0.0069, -0.0001, -0.0001],\n",
      "        ...,\n",
      "        [-0.0021, -0.0017, -0.0174,  ..., -0.0008,  0.0020, -0.0020],\n",
      "        [ 0.0258, -0.0058,  0.0010,  ..., -0.0016,  0.0064,  0.0028],\n",
      "        [-0.0086,  0.0079, -0.0055,  ...,  0.0166,  0.0117, -0.0013]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.1530e-02,  6.6950e-03, -2.0957e-03,  ..., -2.8322e-02,\n",
      "         -3.7940e-03, -5.2455e-03],\n",
      "        [ 7.2819e-03,  9.5673e-04, -7.8130e-03,  ..., -6.1351e-03,\n",
      "          1.9858e-02, -2.8864e-03],\n",
      "        [ 9.9054e-03,  1.9122e-02,  1.0272e-02,  ...,  2.3077e-02,\n",
      "          1.6258e-02, -5.2164e-04],\n",
      "        ...,\n",
      "        [ 7.7508e-03, -8.7552e-03,  7.4690e-03,  ...,  3.9828e-03,\n",
      "          2.5926e-02,  4.5867e-03],\n",
      "        [-1.3801e-02, -1.1098e-02, -1.2701e-02,  ..., -7.8762e-03,\n",
      "         -3.6913e-04, -7.7227e-03],\n",
      "        [ 1.8938e-02,  2.3196e-02, -1.6698e-03,  ...,  2.3063e-02,\n",
      "          9.3833e-05,  1.3218e-03]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ef78b70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.1530e-02,  6.6950e-03, -2.0957e-03,  ..., -2.8322e-02,\n",
      "         -3.7940e-03, -5.2455e-03],\n",
      "        [ 7.2819e-03,  9.5673e-04, -7.8130e-03,  ..., -6.1351e-03,\n",
      "          1.9858e-02, -2.8864e-03],\n",
      "        [ 9.9054e-03,  1.9122e-02,  1.0272e-02,  ...,  2.3077e-02,\n",
      "          1.6258e-02, -5.2164e-04],\n",
      "        ...,\n",
      "        [ 7.7508e-03, -8.7552e-03,  7.4690e-03,  ...,  3.9828e-03,\n",
      "          2.5926e-02,  4.5867e-03],\n",
      "        [-1.3801e-02, -1.1098e-02, -1.2701e-02,  ..., -7.8762e-03,\n",
      "         -3.6913e-04, -7.7227e-03],\n",
      "        [ 1.8938e-02,  2.3196e-02, -1.6698e-03,  ...,  2.3063e-02,\n",
      "          9.3833e-05,  1.3218e-03]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "before_user_em = copy.deepcopy(model.user_em.weight)\n",
    "before_item_em = copy.deepcopy(model.item_em.weight)\n",
    "print(before_item_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "36be3ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        x = self.X[idx]\n",
    "        y = torch.tensor(self.Y[idx]).to(torch.float32)\n",
    "        return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a6ff9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset & DataLoader\n",
    "train_dataset = CustomDataset(X_train, Y_train)\n",
    "test_dataset = CustomDataset(X_test, Y_test)\n",
    "\n",
    "Batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size = Batch_size, shuffle = True, drop_last = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = Batch_size, shuffle = False, drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c0644bef",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, but got 2D and 2D tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [102]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m x,y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\이규석\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36mMF.forward\u001b[1;34m(self, user, item)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,user,item):\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_em\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_em\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 1D tensors expected, but got 2D and 2D tensors"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(train_loader))\n",
    "\n",
    "model(x[0],x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34932a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b04a1161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 15.972427368164062\n",
      "cost = 25719676.0\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [72]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m cost \u001b[38;5;241m=\u001b[39m loss(pred, torch\u001b[38;5;241m.\u001b[39mtensor(Y_train[idx])\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mcost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m      9\u001b[0m total_cost\u001b[38;5;241m.\u001b[39mappend(total_cost)\n",
      "File \u001b[1;32mc:\\users\\이규석\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\이규석\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 본격적인 학습\n",
    "total_cost = []\n",
    "for idx, (user,item) in enumerate(X_train):\n",
    "    pred = model(user-1, item-1)\n",
    "    cost = loss(pred, torch.tensor(Y_train[idx]).to(torch.float32))\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    total_cost.append(total_cost)\n",
    "    if (idx+1) % 1000 == 0:\n",
    "        print(f\"cost = {cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5df1fd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0120, -0.0129, -0.0108,  0.0001, -0.0050,  0.0132,  0.0187,  0.0013,\n",
       "        -0.0029, -0.0037], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.user_em.weight[user-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "918ca9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0120, -0.0129, -0.0108,  0.0001, -0.0050,  0.0132,  0.0187,  0.0013,\n",
       "        -0.0029, -0.0037], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_user_em[user-2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
