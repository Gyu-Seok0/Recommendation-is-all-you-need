{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cd2294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a56fe",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bcd06b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "365d38e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset\n",
    "path = \"/data/gyuseok/ml-latest-small/ratings.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5b4e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# userid\n",
    "users = df.userId.unique()\n",
    "user_id = {value: idx for idx,value in enumerate(users)}\n",
    "df[\"userId\"] = df[\"userId\"].apply(lambda x: user_id[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "521719de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# itemid\n",
    "items = df.movieId.unique()\n",
    "item_id = {value: idx for idx, value in enumerate(items)}\n",
    "df[\"movieId\"] = df[\"movieId\"].apply(lambda x: item_id[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9db7974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users = 610, num_items = 9724\n"
     ]
    }
   ],
   "source": [
    "# num\n",
    "num_users = df[\"userId\"].nunique()\n",
    "num_items = df[\"movieId\"].nunique()\n",
    "print(f\"num_users = {num_users}, num_items = {num_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ae79509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"userId\",\"movieId\"]]\n",
    "df.columns = [\"user\", \"item\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f4fabe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "user_item_interact = defaultdict(list)\n",
    "user_item_interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19fa679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "user_item_interact = defaultdict(list)\n",
    "for row in df.itertuples():\n",
    "    user_item_interact[row.user].append(row.item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a1f9bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-core\n",
    "k = 10\n",
    "for user, items in user_item_interact.items():\n",
    "    if len(items) < k:\n",
    "        print(user, len(items))\n",
    "        del user_item_interact[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ce3624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train & test & valid\n",
    "test_size = 0.1\n",
    "train_dict = defaultdict(list)\n",
    "valid_dict = defaultdict(list)\n",
    "test_dict = defaultdict(list)\n",
    "\n",
    "# item split\n",
    "for user in user_item_interact:\n",
    "    \n",
    "    items = user_item_interact[user]\n",
    "    np.random.shuffle(items)\n",
    "    num_test_items = int(len(items) * test_size)\n",
    "    \n",
    "    test_items = items[:num_test_items]\n",
    "    valid_items = items[num_test_items:num_test_items*2]\n",
    "    train_items = items[num_test_items*2:]\n",
    "    \n",
    "    # assign\n",
    "    test_dict[user] = test_items\n",
    "    valid_dict[user] = valid_items\n",
    "    train_dict[user] = train_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e186c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering\n",
    "train_mat_R = defaultdict(list)\n",
    "for user in train_dict:\n",
    "    for item in train_dict[user]:\n",
    "        train_mat_R[item].append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "769d02d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in list(valid_dict.keys()):\n",
    "    for i in list(valid_dict[u]):\n",
    "        if i not in train_mat_R:\n",
    "            valid_dict[u].remove(i)\n",
    "    \n",
    "    if len(valid_dict[u]) == 0:\n",
    "        del valid_dict[u]\n",
    "        del test_dict[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "acad6677",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in list(test_dict.keys()):\n",
    "    for i in list(test_dict[u]):\n",
    "        if i not in train_mat_R:\n",
    "            test_dict[u].remove(i)\n",
    "\n",
    "    if len(test_dict[u]) == 0:\n",
    "        del valid_dict[u]\n",
    "        del test_dict[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6bdf194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pair(dic:dict):\n",
    "    pairs = []\n",
    "    for u in dic.keys():\n",
    "        for i in dic[u]:\n",
    "            pairs.append((u, i))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d4a53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pair = create_pair(train_dict)\n",
    "# valid_pair = create_pair(valid_dict)\n",
    "# test_pair = create_pair(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d275450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9724"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0979883e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9bbd2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CF_Train_dataset(Dataset):\n",
    "    def __init__(self, train_dict, num_items, num_sample):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.train_dict = train_dict\n",
    "        self.train_arr = []\n",
    "        \n",
    "        self.num_sample = num_sample\n",
    "        self.all_items = set(range(num_items))\n",
    "        self.length = 0\n",
    "        \n",
    "        for u in list(train_dict.keys()):\n",
    "            self.length += len(train_dict[u])\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length * self.num_sample\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        assert self.train_arr\n",
    "        user, pos_item, neg_item = self.train_arr[idx]\n",
    "        return user, pos_item, neg_item\n",
    "    \n",
    "    def negative_sampling(self):\n",
    "        \n",
    "        for u in list(train_dict.keys()):\n",
    "            pos_items = set(train_dict[u])\n",
    "            candidate_items = list(self.all_items - pos_items)\n",
    "            neg_items = np.random.choice(candidate_items, size = len(pos_items) * self.num_sample)\n",
    "            \n",
    "            for idx, pos_i in enumerate(pos_items):\n",
    "                neg_start = idx * self.num_sample\n",
    "                neg_end = (idx + 1) * self.num_sample\n",
    "                \n",
    "                for neg_i in neg_items[neg_start:neg_end]:\n",
    "                    self.train_arr.append((u, pos_i, neg_i))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c7d57abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CF_Test_dataset(Dataset):\n",
    "    def __init__(self, test_dict):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.test_dict = test_dict\n",
    "        self.test_pairs = [(u, i) for u in list(test_dict.keys()) for i in test_dict[u]]\n",
    "        self.length = len(self.test_pairs)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user, pos_item = self.test_pairs[idx]\n",
    "        return user, pos_item\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a09ed68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "\n",
    "num_sample = 2\n",
    "train_dataset = CF_Train_dataset(train_dict, num_items, num_sample)\n",
    "valid_dataset = CF_Test_dataset(valid_dict)\n",
    "test_dataset = CF_Test_dataset(test_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f75b7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 2048\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size,\n",
    "                          shuffle = True, drop_last = False) # 여기서 바로 tensor 주는듯.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f599d51a",
   "metadata": {},
   "source": [
    "# LightGCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c707be4c",
   "metadata": {},
   "source": [
    "## Step1: Making the symmetrically normalized matrix (SNM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "07a76eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "R = torch.zeros(num_users,num_items)\n",
    "\n",
    "# interaction\n",
    "for row in df.itertuples():\n",
    "    R[row.user][row.item] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c9f38a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zero_top = torch.zeros(num_users,num_users)\n",
    "Zero_under = torch.zeros(num_items, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d7c1bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = torch.cat([Zero_top, R], dim = 1)\n",
    "lower = torch.cat([R.T, Zero_under], dim = 1)\n",
    "Adj_mat = torch.cat([upper,lower])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6f0179ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(Adj_mat[:num_users, num_users:], R)\n",
    "torch.allclose(Adj_mat[num_users:, :num_users], R.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b3384889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10334, 10334])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adj_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f3a7157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = torch.cat([torch.sum(R,dim = 1), torch.sum(R,dim = 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d95c1abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10334, 10334])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = torch.diag(interactions)\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7ad1aa3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0657, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.1857, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.1601,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_D = torch.sqrt(1/D)\n",
    "half_D[half_D == float(\"inf\")] = 0\n",
    "half_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d038ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# symmetrically normalized matrix\n",
    "SNM = (half_D @ Adj_mat @ half_D).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f43da05",
   "metadata": {},
   "source": [
    "## Step2: Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7dba4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_users, num_items, emb_size, SNM, num_layers, last_only_use = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embs = nn.Embedding(num_users + num_items, emb_size)\n",
    "        self.SNM = SNM\n",
    "        self.num_layer = num_layers\n",
    "        self.num_users = num_users\n",
    "        self.last_only_use = last_only_use\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.embs.weight)\n",
    "    \n",
    "    def get_embs(self):\n",
    "        embs = self.embs.weight\n",
    "        all_embs = [embs]\n",
    "\n",
    "        # propagation\n",
    "        for _ in range(self.num_layer):\n",
    "            embs = self.SNM @ embs\n",
    "            all_embs.append(embs)\n",
    "        \n",
    "        if self.last_only_use:\n",
    "            return all_embs[-1]\n",
    "        else:\n",
    "            return torch.mean(torch.stack(all_embs), dim = 0)\n",
    "    \n",
    "    \n",
    "    def get_score(self):\n",
    "        embs = self.get_embs()\n",
    "        user_emb = embs[:self.num_users]\n",
    "        item_emb = embs[self.num_users:]\n",
    "        \n",
    "        score = user_emb @ item_emb.T     \n",
    "        return score\n",
    "        \n",
    "        \n",
    "    def forward(self, users, pos_items, neg_items):\n",
    "        \n",
    "        embs = self.get_embs()\n",
    "        \n",
    "        # user, item embedding for Batch  \n",
    "        user_emb = embs[users]\n",
    "        pos_item_emb = embs[pos_items + self.num_users - 1] # adjust the index\n",
    "        neg_item_emb = embs[neg_items + self.num_users - 1] # adjust the index\n",
    "        \n",
    "        # score\n",
    "        pos_score = (user_emb * pos_item_emb).sum(dim = -1)\n",
    "        neg_score = (user_emb * neg_item_emb).sum(dim = -1)\n",
    "        \n",
    "        return pos_score, neg_score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "45c588dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "emb_size = 64\n",
    "num_layers = 4\n",
    "last_only_use = False\n",
    "model = LightGCN(num_users, num_items, emb_size, SNM, num_layers, last_only_use).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357d57fc",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9a2d7328",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9f464627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def to_np(x):\n",
    "    return x.detach().cpu().numpy()\n",
    "\n",
    "def create_metrics(k_list):\n",
    "    metrics = {}\n",
    "    for k in k_list:\n",
    "        for metric in [\"Hit\",\"Recall\",\"NDCG\"]:\n",
    "            metrics[f'{metric}_{k}'] = []\n",
    "\n",
    "    eval_results = {'valid' : copy.deepcopy(metrics), 'test': copy.deepcopy(metrics)}\n",
    "    return eval_results\n",
    "\n",
    "def get_eval(train_mat, valid_mat, test_mat, sorted_mat, k_list):\n",
    "    \n",
    "    max_k = max(k_list)\n",
    "    eval_results = create_metrics(k_list)\n",
    "    \n",
    "    for test_user in test_mat:\n",
    "\n",
    "        sorted_list = to_np(sorted_mat[test_user])\n",
    "\n",
    "        for mode in [\"valid\",'test']:\n",
    "\n",
    "            if mode == \"valid\":\n",
    "                gt_mat = valid_mat\n",
    "                already_seen_items = set(train_mat[test_user]) | set(test_mat[test_user])\n",
    "\n",
    "            elif mode == \"test\":\n",
    "                gt_mat = test_mat\n",
    "                already_seen_items = set(train_mat[test_user]) | set(valid_mat[test_user])\n",
    "\n",
    "            sorted_list_tmp = []\n",
    "            for item in sorted_list:\n",
    "                if item not in already_seen_items:\n",
    "                    sorted_list_tmp.append(item)\n",
    "\n",
    "                if len(sorted_list_tmp) > max_k: break\n",
    "\n",
    "            for k in k_list:\n",
    "                hit_k = len(set(sorted_list_tmp[:k]) & set(gt_mat[test_user]))\n",
    "\n",
    "                # Hit & Recall\n",
    "                eval_results[mode][f\"Hit_{k}\"].append(hit_k / k)\n",
    "                eval_results[mode][f\"Recall_{k}\"].append(hit_k / len(gt_mat[test_user]))\n",
    "\n",
    "                # NDCG\n",
    "                denom = np.log2(np.arange(2, k+2))\n",
    "                dcg_k = np.sum(np.in1d(sorted_list_tmp[:k], gt_mat[test_user]) / denom)\n",
    "                idcg_k = np.sum((1 / denom)[:min(len(gt_mat[test_user]), k)])\n",
    "                NDCG_k = dcg_k / idcg_k\n",
    "\n",
    "                eval_results[mode][f\"NDCG_{k}\"].append(NDCG_k)\n",
    "\n",
    "    # average\n",
    "    for mode in [\"valid\", \"test\"]:\n",
    "        for k in k_list:\n",
    "            eval_results[mode][f\"Hit_{k}\"] = round(np.mean(eval_results[mode][f\"Hit_{k}\"]), 4)\n",
    "            eval_results[mode][f\"Recall_{k}\"] = round(np.mean(eval_results[mode][f\"Recall_{k}\"]), 4)\n",
    "            eval_results[mode][f\"NDCG_{k}\"] = round(np.mean(eval_results[mode][f\"NDCG_{k}\"]), 4)\n",
    "    return eval_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "03631c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'valid': {'Hit_20': 0.0887, 'Recall_20': 0.1665, 'NDCG_20': 0.1605},\n",
       " 'test': {'Hit_20': 0.0875, 'Recall_20': 0.1667, 'NDCG_20': 0.1613}}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_eval(train_dict, valid_dict, test_dict, sorted_mat, k_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb9e19",
   "metadata": {},
   "source": [
    "# Train & Val & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "39a45ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 50\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = 1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "cca5a47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:0]\n",
      "train_loss = 1318.4502\n",
      "{'valid': {'Hit_20': 0.0711, 'Recall_20': 0.1279, 'NDCG_20': 0.1266}, 'test': {'Hit_20': 0.0699, 'Recall_20': 0.1219, 'NDCG_20': 0.1261}}\n",
      "\n",
      "[Epoch:1]\n",
      "train_loss = 1011.9600\n",
      "{'valid': {'Hit_20': 0.0706, 'Recall_20': 0.1262, 'NDCG_20': 0.1261}, 'test': {'Hit_20': 0.0684, 'Recall_20': 0.1221, 'NDCG_20': 0.1242}}\n",
      "\n",
      "[Epoch:2]\n",
      "train_loss = 882.7140\n",
      "{'valid': {'Hit_20': 0.0702, 'Recall_20': 0.1258, 'NDCG_20': 0.1255}, 'test': {'Hit_20': 0.0665, 'Recall_20': 0.1217, 'NDCG_20': 0.1225}}\n",
      "\n",
      "[Epoch:3]\n",
      "train_loss = 820.2934\n",
      "{'valid': {'Hit_20': 0.0686, 'Recall_20': 0.1236, 'NDCG_20': 0.1248}, 'test': {'Hit_20': 0.0654, 'Recall_20': 0.1221, 'NDCG_20': 0.1209}}\n",
      "\n",
      "[Epoch:4]\n",
      "train_loss = 776.6343\n",
      "{'valid': {'Hit_20': 0.0676, 'Recall_20': 0.1213, 'NDCG_20': 0.1235}, 'test': {'Hit_20': 0.0639, 'Recall_20': 0.1208, 'NDCG_20': 0.1196}}\n",
      "\n",
      "[Epoch:5]\n",
      "train_loss = 743.0702\n",
      "{'valid': {'Hit_20': 0.0672, 'Recall_20': 0.12, 'NDCG_20': 0.1226}, 'test': {'Hit_20': 0.0624, 'Recall_20': 0.1165, 'NDCG_20': 0.1175}}\n",
      "\n",
      "[Epoch:6]\n",
      "train_loss = 716.0883\n",
      "{'valid': {'Hit_20': 0.0665, 'Recall_20': 0.1179, 'NDCG_20': 0.1213}, 'test': {'Hit_20': 0.0614, 'Recall_20': 0.1157, 'NDCG_20': 0.1152}}\n",
      "\n",
      "[Epoch:7]\n",
      "train_loss = 693.7033\n",
      "{'valid': {'Hit_20': 0.0653, 'Recall_20': 0.1171, 'NDCG_20': 0.1204}, 'test': {'Hit_20': 0.0607, 'Recall_20': 0.1143, 'NDCG_20': 0.114}}\n",
      "\n",
      "[Epoch:8]\n",
      "train_loss = 674.5328\n",
      "{'valid': {'Hit_20': 0.0647, 'Recall_20': 0.1162, 'NDCG_20': 0.1196}, 'test': {'Hit_20': 0.0595, 'Recall_20': 0.113, 'NDCG_20': 0.1125}}\n",
      "\n",
      "[Epoch:9]\n",
      "train_loss = 657.4215\n",
      "{'valid': {'Hit_20': 0.0641, 'Recall_20': 0.116, 'NDCG_20': 0.1178}, 'test': {'Hit_20': 0.0588, 'Recall_20': 0.1134, 'NDCG_20': 0.11}}\n",
      "\n",
      "[Epoch:10]\n",
      "train_loss = 641.7505\n",
      "{'valid': {'Hit_20': 0.0639, 'Recall_20': 0.1174, 'NDCG_20': 0.1174}, 'test': {'Hit_20': 0.0579, 'Recall_20': 0.1111, 'NDCG_20': 0.1082}}\n",
      "\n",
      "[Epoch:11]\n",
      "train_loss = 626.6169\n",
      "{'valid': {'Hit_20': 0.0633, 'Recall_20': 0.1156, 'NDCG_20': 0.1164}, 'test': {'Hit_20': 0.0573, 'Recall_20': 0.1092, 'NDCG_20': 0.1071}}\n",
      "\n",
      "[Epoch:12]\n",
      "train_loss = 611.3506\n",
      "{'valid': {'Hit_20': 0.0625, 'Recall_20': 0.1156, 'NDCG_20': 0.1158}, 'test': {'Hit_20': 0.0568, 'Recall_20': 0.1085, 'NDCG_20': 0.1064}}\n",
      "\n",
      "[Epoch:13]\n",
      "train_loss = 595.3221\n",
      "{'valid': {'Hit_20': 0.062, 'Recall_20': 0.1154, 'NDCG_20': 0.1145}, 'test': {'Hit_20': 0.0561, 'Recall_20': 0.1079, 'NDCG_20': 0.105}}\n",
      "\n",
      "[Epoch:14]\n",
      "train_loss = 578.2635\n",
      "{'valid': {'Hit_20': 0.0615, 'Recall_20': 0.1138, 'NDCG_20': 0.1109}, 'test': {'Hit_20': 0.0555, 'Recall_20': 0.1068, 'NDCG_20': 0.1036}}\n",
      "\n",
      "[Epoch:15]\n",
      "train_loss = 560.7068\n",
      "{'valid': {'Hit_20': 0.0619, 'Recall_20': 0.1147, 'NDCG_20': 0.1108}, 'test': {'Hit_20': 0.0561, 'Recall_20': 0.1074, 'NDCG_20': 0.1038}}\n",
      "\n",
      "[Epoch:16]\n",
      "train_loss = 543.4589\n",
      "{'valid': {'Hit_20': 0.0613, 'Recall_20': 0.113, 'NDCG_20': 0.1096}, 'test': {'Hit_20': 0.0558, 'Recall_20': 0.1082, 'NDCG_20': 0.1042}}\n",
      "\n",
      "[Epoch:17]\n",
      "train_loss = 527.2251\n",
      "{'valid': {'Hit_20': 0.0606, 'Recall_20': 0.112, 'NDCG_20': 0.1089}, 'test': {'Hit_20': 0.0557, 'Recall_20': 0.1059, 'NDCG_20': 0.1039}}\n",
      "\n",
      "[Epoch:18]\n",
      "train_loss = 512.3884\n",
      "{'valid': {'Hit_20': 0.0614, 'Recall_20': 0.1125, 'NDCG_20': 0.1092}, 'test': {'Hit_20': 0.0564, 'Recall_20': 0.1066, 'NDCG_20': 0.1043}}\n",
      "\n",
      "[Epoch:19]\n",
      "train_loss = 498.9578\n",
      "{'valid': {'Hit_20': 0.0616, 'Recall_20': 0.1115, 'NDCG_20': 0.1085}, 'test': {'Hit_20': 0.0559, 'Recall_20': 0.1061, 'NDCG_20': 0.1034}}\n",
      "\n",
      "[Epoch:20]\n",
      "train_loss = 486.7172\n",
      "{'valid': {'Hit_20': 0.061, 'Recall_20': 0.1116, 'NDCG_20': 0.1072}, 'test': {'Hit_20': 0.055, 'Recall_20': 0.1051, 'NDCG_20': 0.1016}}\n",
      "\n",
      "[Epoch:21]\n",
      "train_loss = 475.5089\n",
      "{'valid': {'Hit_20': 0.0602, 'Recall_20': 0.1095, 'NDCG_20': 0.105}, 'test': {'Hit_20': 0.0552, 'Recall_20': 0.1046, 'NDCG_20': 0.1004}}\n",
      "\n",
      "[Epoch:22]\n",
      "train_loss = 465.0358\n",
      "{'valid': {'Hit_20': 0.0598, 'Recall_20': 0.1084, 'NDCG_20': 0.1037}, 'test': {'Hit_20': 0.0548, 'Recall_20': 0.1034, 'NDCG_20': 0.099}}\n",
      "\n",
      "[Epoch:23]\n",
      "train_loss = 455.2335\n",
      "{'valid': {'Hit_20': 0.0593, 'Recall_20': 0.1071, 'NDCG_20': 0.1039}, 'test': {'Hit_20': 0.0539, 'Recall_20': 0.1023, 'NDCG_20': 0.0977}}\n",
      "\n",
      "[Epoch:24]\n",
      "train_loss = 445.8020\n",
      "{'valid': {'Hit_20': 0.0579, 'Recall_20': 0.1039, 'NDCG_20': 0.1029}, 'test': {'Hit_20': 0.0527, 'Recall_20': 0.0996, 'NDCG_20': 0.0956}}\n",
      "\n",
      "[Epoch:25]\n",
      "train_loss = 436.8046\n",
      "{'valid': {'Hit_20': 0.0576, 'Recall_20': 0.1027, 'NDCG_20': 0.1011}, 'test': {'Hit_20': 0.0516, 'Recall_20': 0.0971, 'NDCG_20': 0.0936}}\n",
      "\n",
      "[Epoch:26]\n",
      "train_loss = 428.1406\n",
      "{'valid': {'Hit_20': 0.0568, 'Recall_20': 0.1016, 'NDCG_20': 0.0994}, 'test': {'Hit_20': 0.0507, 'Recall_20': 0.095, 'NDCG_20': 0.0921}}\n",
      "\n",
      "[Epoch:27]\n",
      "train_loss = 419.7842\n",
      "{'valid': {'Hit_20': 0.0558, 'Recall_20': 0.0975, 'NDCG_20': 0.0973}, 'test': {'Hit_20': 0.0498, 'Recall_20': 0.0939, 'NDCG_20': 0.0906}}\n",
      "\n",
      "[Epoch:28]\n",
      "train_loss = 411.8011\n",
      "{'valid': {'Hit_20': 0.0547, 'Recall_20': 0.0956, 'NDCG_20': 0.0956}, 'test': {'Hit_20': 0.0499, 'Recall_20': 0.0935, 'NDCG_20': 0.0898}}\n",
      "\n",
      "[Epoch:29]\n",
      "train_loss = 404.0803\n",
      "{'valid': {'Hit_20': 0.0542, 'Recall_20': 0.096, 'NDCG_20': 0.0945}, 'test': {'Hit_20': 0.0495, 'Recall_20': 0.0931, 'NDCG_20': 0.0886}}\n",
      "\n",
      "[Epoch:30]\n",
      "train_loss = 396.6702\n",
      "{'valid': {'Hit_20': 0.0537, 'Recall_20': 0.0964, 'NDCG_20': 0.0936}, 'test': {'Hit_20': 0.0489, 'Recall_20': 0.0923, 'NDCG_20': 0.0878}}\n",
      "\n",
      "[Epoch:31]\n",
      "train_loss = 389.4870\n",
      "{'valid': {'Hit_20': 0.0528, 'Recall_20': 0.0944, 'NDCG_20': 0.0914}, 'test': {'Hit_20': 0.0482, 'Recall_20': 0.0915, 'NDCG_20': 0.0863}}\n",
      "\n",
      "[Epoch:32]\n",
      "train_loss = 382.5999\n",
      "{'valid': {'Hit_20': 0.0523, 'Recall_20': 0.093, 'NDCG_20': 0.0895}, 'test': {'Hit_20': 0.0482, 'Recall_20': 0.0912, 'NDCG_20': 0.0854}}\n",
      "\n",
      "[Epoch:33]\n",
      "train_loss = 375.8864\n",
      "{'valid': {'Hit_20': 0.0521, 'Recall_20': 0.0928, 'NDCG_20': 0.0878}, 'test': {'Hit_20': 0.0475, 'Recall_20': 0.0912, 'NDCG_20': 0.0845}}\n",
      "\n",
      "[Epoch:34]\n",
      "train_loss = 369.3998\n",
      "{'valid': {'Hit_20': 0.0513, 'Recall_20': 0.0918, 'NDCG_20': 0.0861}, 'test': {'Hit_20': 0.047, 'Recall_20': 0.0898, 'NDCG_20': 0.0826}}\n",
      "\n",
      "[Epoch:35]\n",
      "train_loss = 363.0758\n",
      "{'valid': {'Hit_20': 0.0507, 'Recall_20': 0.0915, 'NDCG_20': 0.0855}, 'test': {'Hit_20': 0.0464, 'Recall_20': 0.0869, 'NDCG_20': 0.0808}}\n",
      "\n",
      "[Epoch:36]\n",
      "train_loss = 356.9184\n",
      "{'valid': {'Hit_20': 0.0505, 'Recall_20': 0.0909, 'NDCG_20': 0.0845}, 'test': {'Hit_20': 0.0457, 'Recall_20': 0.0858, 'NDCG_20': 0.0799}}\n",
      "\n",
      "[Epoch:37]\n",
      "train_loss = 350.9216\n",
      "{'valid': {'Hit_20': 0.0499, 'Recall_20': 0.0902, 'NDCG_20': 0.0838}, 'test': {'Hit_20': 0.0456, 'Recall_20': 0.0857, 'NDCG_20': 0.0794}}\n",
      "\n",
      "[Epoch:38]\n",
      "train_loss = 345.0499\n",
      "{'valid': {'Hit_20': 0.0497, 'Recall_20': 0.0904, 'NDCG_20': 0.0835}, 'test': {'Hit_20': 0.0448, 'Recall_20': 0.084, 'NDCG_20': 0.0783}}\n",
      "\n",
      "[Epoch:39]\n",
      "train_loss = 339.3200\n",
      "{'valid': {'Hit_20': 0.0492, 'Recall_20': 0.0907, 'NDCG_20': 0.0833}, 'test': {'Hit_20': 0.045, 'Recall_20': 0.0839, 'NDCG_20': 0.0783}}\n",
      "\n",
      "[Epoch:40]\n",
      "train_loss = 333.7209\n",
      "{'valid': {'Hit_20': 0.049, 'Recall_20': 0.0907, 'NDCG_20': 0.083}, 'test': {'Hit_20': 0.0449, 'Recall_20': 0.0834, 'NDCG_20': 0.078}}\n",
      "\n",
      "[Epoch:41]\n",
      "train_loss = 328.2210\n",
      "{'valid': {'Hit_20': 0.0487, 'Recall_20': 0.0907, 'NDCG_20': 0.0834}, 'test': {'Hit_20': 0.0452, 'Recall_20': 0.085, 'NDCG_20': 0.0782}}\n",
      "\n",
      "[Epoch:42]\n",
      "train_loss = 322.8556\n",
      "{'valid': {'Hit_20': 0.0486, 'Recall_20': 0.0901, 'NDCG_20': 0.0832}, 'test': {'Hit_20': 0.0441, 'Recall_20': 0.0834, 'NDCG_20': 0.0764}}\n",
      "\n",
      "[Epoch:43]\n",
      "train_loss = 317.5978\n",
      "{'valid': {'Hit_20': 0.0485, 'Recall_20': 0.09, 'NDCG_20': 0.0839}, 'test': {'Hit_20': 0.0443, 'Recall_20': 0.0849, 'NDCG_20': 0.077}}\n",
      "\n",
      "[Epoch:44]\n",
      "train_loss = 312.4574\n",
      "{'valid': {'Hit_20': 0.0483, 'Recall_20': 0.0898, 'NDCG_20': 0.0832}, 'test': {'Hit_20': 0.0447, 'Recall_20': 0.0856, 'NDCG_20': 0.0774}}\n",
      "\n",
      "[Epoch:45]\n",
      "train_loss = 307.4042\n",
      "{'valid': {'Hit_20': 0.0481, 'Recall_20': 0.0906, 'NDCG_20': 0.0835}, 'test': {'Hit_20': 0.0449, 'Recall_20': 0.086, 'NDCG_20': 0.0782}}\n",
      "\n",
      "[Epoch:46]\n",
      "train_loss = 302.4640\n",
      "{'valid': {'Hit_20': 0.0481, 'Recall_20': 0.0912, 'NDCG_20': 0.0836}, 'test': {'Hit_20': 0.0451, 'Recall_20': 0.0862, 'NDCG_20': 0.0781}}\n",
      "\n",
      "[Epoch:47]\n",
      "train_loss = 297.6080\n",
      "{'valid': {'Hit_20': 0.048, 'Recall_20': 0.0921, 'NDCG_20': 0.0837}, 'test': {'Hit_20': 0.0451, 'Recall_20': 0.0864, 'NDCG_20': 0.078}}\n",
      "\n",
      "[Epoch:48]\n",
      "train_loss = 292.8515\n",
      "{'valid': {'Hit_20': 0.0478, 'Recall_20': 0.0917, 'NDCG_20': 0.0833}, 'test': {'Hit_20': 0.045, 'Recall_20': 0.0867, 'NDCG_20': 0.0784}}\n",
      "\n",
      "[Epoch:49]\n",
      "train_loss = 288.2038\n",
      "{'valid': {'Hit_20': 0.048, 'Recall_20': 0.091, 'NDCG_20': 0.0836}, 'test': {'Hit_20': 0.0449, 'Recall_20': 0.0876, 'NDCG_20': 0.0787}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# layer = 4, neg_sample = 2, last_only_use = False, lr = 0.001 -> 단순 aggreagation은 overfitting을 심화시킴.\n",
    "\n",
    "def cpu2gpu(data, device):\n",
    "    return list(map(lambda x: x.to(device), data))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"[Epoch:{epoch}]\")\n",
    "    train_loader.dataset.negative_sampling()\n",
    "    train_loss = 0\n",
    "    for data in train_loader:\n",
    "        u, i, j = cpu2gpu(data, device)\n",
    "        \n",
    "        # forward\n",
    "        pos_score, neg_score = model(u,i,j)\n",
    "        #loss = -(pos_score - neg_score).sigmoid().log().sum()\n",
    "        \n",
    "        # to solve nan problem\n",
    "        loss = (pos_score - neg_score).sigmoid()\n",
    "        loss = torch.where(loss < 0.9999, loss, 0.9999)\n",
    "        loss = torch.where(loss > 0.0001, loss, 0.0001)\n",
    "        loss = -loss.log().sum()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    score_mat = model.get_score()\n",
    "    sorted_mat = torch.argsort(score_mat, dim = 1, descending = True)\n",
    "    results = get_eval(train_dict, valid_dict, test_dict, sorted_mat, k_list)\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"train_loss = {train_loss:.4f}\")\n",
    "    print(results)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f2c06adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:0]\n",
      "train_loss = 1300.0593\n",
      "{'valid': {'Hit_20': 0.0742, 'Recall_20': 0.122, 'NDCG_20': 0.1285}, 'test': {'Hit_20': 0.0721, 'Recall_20': 0.1193, 'NDCG_20': 0.1268}}\n",
      "\n",
      "[Epoch:1]\n",
      "train_loss = 1057.2086\n",
      "{'valid': {'Hit_20': 0.0734, 'Recall_20': 0.1214, 'NDCG_20': 0.1276}, 'test': {'Hit_20': 0.0721, 'Recall_20': 0.117, 'NDCG_20': 0.1263}}\n",
      "\n",
      "[Epoch:2]\n",
      "train_loss = 1032.3338\n",
      "{'valid': {'Hit_20': 0.0743, 'Recall_20': 0.1264, 'NDCG_20': 0.1282}, 'test': {'Hit_20': 0.0717, 'Recall_20': 0.1183, 'NDCG_20': 0.1262}}\n",
      "\n",
      "[Epoch:3]\n",
      "train_loss = 1025.7658\n",
      "{'valid': {'Hit_20': 0.0727, 'Recall_20': 0.1242, 'NDCG_20': 0.1266}, 'test': {'Hit_20': 0.0716, 'Recall_20': 0.1184, 'NDCG_20': 0.1262}}\n",
      "\n",
      "[Epoch:4]\n",
      "train_loss = 1020.3503\n",
      "{'valid': {'Hit_20': 0.0727, 'Recall_20': 0.1261, 'NDCG_20': 0.1267}, 'test': {'Hit_20': 0.0713, 'Recall_20': 0.121, 'NDCG_20': 0.126}}\n",
      "\n",
      "[Epoch:5]\n",
      "train_loss = 1015.5147\n",
      "{'valid': {'Hit_20': 0.0723, 'Recall_20': 0.1257, 'NDCG_20': 0.1262}, 'test': {'Hit_20': 0.071, 'Recall_20': 0.1214, 'NDCG_20': 0.1258}}\n",
      "\n",
      "[Epoch:6]\n",
      "train_loss = 1011.0556\n",
      "{'valid': {'Hit_20': 0.0723, 'Recall_20': 0.1261, 'NDCG_20': 0.1259}, 'test': {'Hit_20': 0.0699, 'Recall_20': 0.1202, 'NDCG_20': 0.1247}}\n",
      "\n",
      "[Epoch:7]\n",
      "train_loss = 1006.7201\n",
      "{'valid': {'Hit_20': 0.0723, 'Recall_20': 0.1276, 'NDCG_20': 0.126}, 'test': {'Hit_20': 0.0692, 'Recall_20': 0.12, 'NDCG_20': 0.1241}}\n",
      "\n",
      "[Epoch:8]\n",
      "train_loss = 1002.6059\n",
      "{'valid': {'Hit_20': 0.0719, 'Recall_20': 0.1269, 'NDCG_20': 0.1256}, 'test': {'Hit_20': 0.0686, 'Recall_20': 0.1197, 'NDCG_20': 0.1237}}\n",
      "\n",
      "[Epoch:9]\n",
      "train_loss = 998.6539\n",
      "{'valid': {'Hit_20': 0.0716, 'Recall_20': 0.1268, 'NDCG_20': 0.1252}, 'test': {'Hit_20': 0.0684, 'Recall_20': 0.1199, 'NDCG_20': 0.1235}}\n",
      "\n",
      "[Epoch:10]\n",
      "train_loss = 994.9049\n",
      "{'valid': {'Hit_20': 0.0713, 'Recall_20': 0.1267, 'NDCG_20': 0.1251}, 'test': {'Hit_20': 0.0682, 'Recall_20': 0.1203, 'NDCG_20': 0.1235}}\n",
      "\n",
      "[Epoch:11]\n",
      "train_loss = 991.3500\n",
      "{'valid': {'Hit_20': 0.0711, 'Recall_20': 0.1259, 'NDCG_20': 0.1248}, 'test': {'Hit_20': 0.0683, 'Recall_20': 0.1219, 'NDCG_20': 0.1245}}\n",
      "\n",
      "[Epoch:12]\n",
      "train_loss = 987.8624\n",
      "{'valid': {'Hit_20': 0.0711, 'Recall_20': 0.1259, 'NDCG_20': 0.1245}, 'test': {'Hit_20': 0.0682, 'Recall_20': 0.1219, 'NDCG_20': 0.1244}}\n",
      "\n",
      "[Epoch:13]\n",
      "train_loss = 984.4403\n",
      "{'valid': {'Hit_20': 0.0711, 'Recall_20': 0.1259, 'NDCG_20': 0.1247}, 'test': {'Hit_20': 0.0683, 'Recall_20': 0.1219, 'NDCG_20': 0.1244}}\n",
      "\n",
      "[Epoch:14]\n",
      "train_loss = 980.9825\n",
      "{'valid': {'Hit_20': 0.0711, 'Recall_20': 0.1265, 'NDCG_20': 0.1248}, 'test': {'Hit_20': 0.068, 'Recall_20': 0.1211, 'NDCG_20': 0.1241}}\n",
      "\n",
      "[Epoch:15]\n",
      "train_loss = 977.3017\n",
      "{'valid': {'Hit_20': 0.0711, 'Recall_20': 0.127, 'NDCG_20': 0.1252}, 'test': {'Hit_20': 0.0683, 'Recall_20': 0.1223, 'NDCG_20': 0.1248}}\n",
      "\n",
      "[Epoch:16]\n",
      "train_loss = 972.9032\n",
      "{'valid': {'Hit_20': 0.0715, 'Recall_20': 0.1273, 'NDCG_20': 0.1254}, 'test': {'Hit_20': 0.0684, 'Recall_20': 0.1225, 'NDCG_20': 0.1251}}\n",
      "\n",
      "[Epoch:17]\n",
      "train_loss = 967.1367\n",
      "{'valid': {'Hit_20': 0.072, 'Recall_20': 0.1282, 'NDCG_20': 0.1268}, 'test': {'Hit_20': 0.0692, 'Recall_20': 0.1231, 'NDCG_20': 0.1263}}\n",
      "\n",
      "[Epoch:18]\n",
      "train_loss = 959.5644\n",
      "{'valid': {'Hit_20': 0.0729, 'Recall_20': 0.1293, 'NDCG_20': 0.1294}, 'test': {'Hit_20': 0.0713, 'Recall_20': 0.127, 'NDCG_20': 0.1294}}\n",
      "\n",
      "[Epoch:19]\n",
      "train_loss = 949.7477\n",
      "{'valid': {'Hit_20': 0.0757, 'Recall_20': 0.1346, 'NDCG_20': 0.1343}, 'test': {'Hit_20': 0.0734, 'Recall_20': 0.1307, 'NDCG_20': 0.1325}}\n",
      "\n",
      "[Epoch:20]\n",
      "train_loss = 938.1503\n",
      "{'valid': {'Hit_20': 0.0771, 'Recall_20': 0.1368, 'NDCG_20': 0.1376}, 'test': {'Hit_20': 0.0748, 'Recall_20': 0.1329, 'NDCG_20': 0.1357}}\n",
      "\n",
      "[Epoch:21]\n",
      "train_loss = 925.3128\n",
      "{'valid': {'Hit_20': 0.0794, 'Recall_20': 0.1424, 'NDCG_20': 0.1427}, 'test': {'Hit_20': 0.0774, 'Recall_20': 0.1382, 'NDCG_20': 0.1419}}\n",
      "\n",
      "[Epoch:22]\n",
      "train_loss = 912.1187\n",
      "{'valid': {'Hit_20': 0.0811, 'Recall_20': 0.1501, 'NDCG_20': 0.1469}, 'test': {'Hit_20': 0.079, 'Recall_20': 0.1428, 'NDCG_20': 0.1446}}\n",
      "\n",
      "[Epoch:23]\n",
      "train_loss = 899.5526\n",
      "{'valid': {'Hit_20': 0.0835, 'Recall_20': 0.157, 'NDCG_20': 0.152}, 'test': {'Hit_20': 0.0828, 'Recall_20': 0.1548, 'NDCG_20': 0.1523}}\n",
      "\n",
      "[Epoch:24]\n",
      "train_loss = 888.5176\n",
      "{'valid': {'Hit_20': 0.0844, 'Recall_20': 0.1624, 'NDCG_20': 0.1557}, 'test': {'Hit_20': 0.0835, 'Recall_20': 0.1613, 'NDCG_20': 0.1547}}\n",
      "\n",
      "[Epoch:25]\n",
      "train_loss = 879.3781\n",
      "{'valid': {'Hit_20': 0.0857, 'Recall_20': 0.1663, 'NDCG_20': 0.1587}, 'test': {'Hit_20': 0.0832, 'Recall_20': 0.1599, 'NDCG_20': 0.1552}}\n",
      "\n",
      "[Epoch:26]\n",
      "train_loss = 872.1623\n",
      "{'valid': {'Hit_20': 0.0866, 'Recall_20': 0.1687, 'NDCG_20': 0.1594}, 'test': {'Hit_20': 0.0848, 'Recall_20': 0.1627, 'NDCG_20': 0.1584}}\n",
      "\n",
      "[Epoch:27]\n",
      "train_loss = 866.4934\n",
      "{'valid': {'Hit_20': 0.0867, 'Recall_20': 0.1689, 'NDCG_20': 0.1602}, 'test': {'Hit_20': 0.0853, 'Recall_20': 0.1647, 'NDCG_20': 0.1604}}\n",
      "\n",
      "[Epoch:28]\n",
      "train_loss = 861.8552\n",
      "{'valid': {'Hit_20': 0.0859, 'Recall_20': 0.1681, 'NDCG_20': 0.1593}, 'test': {'Hit_20': 0.0858, 'Recall_20': 0.1659, 'NDCG_20': 0.1613}}\n",
      "\n",
      "[Epoch:29]\n",
      "train_loss = 857.9175\n",
      "{'valid': {'Hit_20': 0.0856, 'Recall_20': 0.1678, 'NDCG_20': 0.1596}, 'test': {'Hit_20': 0.0859, 'Recall_20': 0.1668, 'NDCG_20': 0.1616}}\n",
      "\n",
      "[Epoch:30]\n",
      "train_loss = 853.8772\n",
      "{'valid': {'Hit_20': 0.0856, 'Recall_20': 0.1675, 'NDCG_20': 0.159}, 'test': {'Hit_20': 0.0863, 'Recall_20': 0.1667, 'NDCG_20': 0.1627}}\n",
      "\n",
      "[Epoch:31]\n",
      "train_loss = 850.1064\n",
      "{'valid': {'Hit_20': 0.0852, 'Recall_20': 0.1672, 'NDCG_20': 0.1587}, 'test': {'Hit_20': 0.0868, 'Recall_20': 0.1662, 'NDCG_20': 0.1628}}\n",
      "\n",
      "[Epoch:32]\n",
      "train_loss = 846.2836\n",
      "{'valid': {'Hit_20': 0.0857, 'Recall_20': 0.1655, 'NDCG_20': 0.1586}, 'test': {'Hit_20': 0.0873, 'Recall_20': 0.1657, 'NDCG_20': 0.1631}}\n",
      "\n",
      "[Epoch:33]\n",
      "train_loss = 842.4675\n",
      "{'valid': {'Hit_20': 0.0864, 'Recall_20': 0.1651, 'NDCG_20': 0.1591}, 'test': {'Hit_20': 0.0874, 'Recall_20': 0.1664, 'NDCG_20': 0.1632}}\n",
      "\n",
      "[Epoch:34]\n",
      "train_loss = 838.6820\n",
      "{'valid': {'Hit_20': 0.0857, 'Recall_20': 0.1629, 'NDCG_20': 0.1578}, 'test': {'Hit_20': 0.0873, 'Recall_20': 0.167, 'NDCG_20': 0.1627}}\n",
      "\n",
      "[Epoch:35]\n",
      "train_loss = 835.1000\n",
      "{'valid': {'Hit_20': 0.0864, 'Recall_20': 0.1636, 'NDCG_20': 0.1585}, 'test': {'Hit_20': 0.0868, 'Recall_20': 0.1653, 'NDCG_20': 0.1622}}\n",
      "\n",
      "[Epoch:36]\n",
      "train_loss = 831.9461\n",
      "{'valid': {'Hit_20': 0.087, 'Recall_20': 0.1627, 'NDCG_20': 0.1586}, 'test': {'Hit_20': 0.088, 'Recall_20': 0.1669, 'NDCG_20': 0.1627}}\n",
      "\n",
      "[Epoch:37]\n",
      "train_loss = 829.1205\n",
      "{'valid': {'Hit_20': 0.0871, 'Recall_20': 0.1626, 'NDCG_20': 0.1593}, 'test': {'Hit_20': 0.0882, 'Recall_20': 0.1676, 'NDCG_20': 0.1628}}\n",
      "\n",
      "[Epoch:38]\n",
      "train_loss = 826.3759\n",
      "{'valid': {'Hit_20': 0.0875, 'Recall_20': 0.1622, 'NDCG_20': 0.1596}, 'test': {'Hit_20': 0.088, 'Recall_20': 0.1685, 'NDCG_20': 0.1634}}\n",
      "\n",
      "[Epoch:39]\n",
      "train_loss = 823.9885\n",
      "{'valid': {'Hit_20': 0.0879, 'Recall_20': 0.1632, 'NDCG_20': 0.16}, 'test': {'Hit_20': 0.0882, 'Recall_20': 0.1667, 'NDCG_20': 0.1632}}\n",
      "\n",
      "[Epoch:40]\n",
      "train_loss = 821.7196\n",
      "{'valid': {'Hit_20': 0.0884, 'Recall_20': 0.1651, 'NDCG_20': 0.161}, 'test': {'Hit_20': 0.0883, 'Recall_20': 0.1669, 'NDCG_20': 0.1635}}\n",
      "\n",
      "[Epoch:41]\n",
      "train_loss = 819.5782\n",
      "{'valid': {'Hit_20': 0.0883, 'Recall_20': 0.1636, 'NDCG_20': 0.1603}, 'test': {'Hit_20': 0.0883, 'Recall_20': 0.167, 'NDCG_20': 0.1635}}\n",
      "\n",
      "[Epoch:42]\n",
      "train_loss = 817.6277\n",
      "{'valid': {'Hit_20': 0.0882, 'Recall_20': 0.1639, 'NDCG_20': 0.1604}, 'test': {'Hit_20': 0.0883, 'Recall_20': 0.1681, 'NDCG_20': 0.1633}}\n",
      "\n",
      "[Epoch:43]\n",
      "train_loss = 815.8080\n",
      "{'valid': {'Hit_20': 0.0884, 'Recall_20': 0.1642, 'NDCG_20': 0.1603}, 'test': {'Hit_20': 0.0876, 'Recall_20': 0.1658, 'NDCG_20': 0.1622}}\n",
      "\n",
      "[Epoch:44]\n",
      "train_loss = 814.0269\n",
      "{'valid': {'Hit_20': 0.0895, 'Recall_20': 0.1654, 'NDCG_20': 0.1616}, 'test': {'Hit_20': 0.0876, 'Recall_20': 0.1643, 'NDCG_20': 0.1617}}\n",
      "\n",
      "[Epoch:45]\n",
      "train_loss = 812.3839\n",
      "{'valid': {'Hit_20': 0.0888, 'Recall_20': 0.1646, 'NDCG_20': 0.1609}, 'test': {'Hit_20': 0.0876, 'Recall_20': 0.1649, 'NDCG_20': 0.1623}}\n",
      "\n",
      "[Epoch:46]\n",
      "train_loss = 810.9132\n",
      "{'valid': {'Hit_20': 0.089, 'Recall_20': 0.1658, 'NDCG_20': 0.1606}, 'test': {'Hit_20': 0.0882, 'Recall_20': 0.1675, 'NDCG_20': 0.1627}}\n",
      "\n",
      "[Epoch:47]\n",
      "train_loss = 809.3093\n",
      "{'valid': {'Hit_20': 0.0893, 'Recall_20': 0.1665, 'NDCG_20': 0.162}, 'test': {'Hit_20': 0.0884, 'Recall_20': 0.1653, 'NDCG_20': 0.1624}}\n",
      "\n",
      "[Epoch:48]\n",
      "train_loss = 807.9718\n",
      "{'valid': {'Hit_20': 0.089, 'Recall_20': 0.166, 'NDCG_20': 0.1612}, 'test': {'Hit_20': 0.0877, 'Recall_20': 0.1642, 'NDCG_20': 0.1611}}\n",
      "\n",
      "[Epoch:49]\n",
      "train_loss = 806.5396\n",
      "{'valid': {'Hit_20': 0.0887, 'Recall_20': 0.1665, 'NDCG_20': 0.1605}, 'test': {'Hit_20': 0.0875, 'Recall_20': 0.1667, 'NDCG_20': 0.1613}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# layer = 4, neg_sample = 2, last_only_use = True, lr = 0.001\n",
    "\n",
    "def cpu2gpu(data, device):\n",
    "    return list(map(lambda x: x.to(device), data))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"[Epoch:{epoch}]\")\n",
    "    train_loader.dataset.negative_sampling()\n",
    "    train_loss = 0\n",
    "    for data in train_loader:\n",
    "        u, i, j = cpu2gpu(data, device)\n",
    "        \n",
    "        # forward\n",
    "        pos_score, neg_score = model(u,i,j)\n",
    "        #loss = -(pos_score - neg_score).sigmoid().log().sum()\n",
    "        \n",
    "        # to solve nan problem\n",
    "        loss = (pos_score - neg_score).sigmoid()\n",
    "        loss = torch.where(loss < 0.9999, loss, 0.9999)\n",
    "        loss = torch.where(loss > 0.0001, loss, 0.0001)\n",
    "        loss = -loss.log().sum()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    score_mat = model.get_score()\n",
    "    sorted_mat = torch.argsort(score_mat, dim = 1, descending = True)\n",
    "    results = get_eval(train_dict, valid_dict, test_dict, sorted_mat, k_list)\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"train_loss = {train_loss:.4f}\")\n",
    "    print(results)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c91e6f2",
   "metadata": {},
   "source": [
    "# 결론\n",
    "\n",
    "1) layer의 깊이가 4일때 가장 좋은 성능을 얻음 (i.e., NDCG20이 0.16대 진입) <br>\n",
    "2) last_only_user가 True일때 가장 좋은 성능을 얻음 (모든 layer에 대한 average를 취하면, overfitting 현상 발생함) <br>\n",
    "3) neg_sample의 개수가 2일 때가 가장 좋음 (개수를 높이면 overfitting 현상 발생) <br>\n",
    "4) lr가 0.001일 때가 가장 좋음 (lr을 높이면 overfitting 현상 발생) <br>\n",
    "\n",
    "결론: [layer = 4, neg_sample = 2, last_only_use = True, lr = 0.001] 에서 가장 좋은 성능을 보임!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2182979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
